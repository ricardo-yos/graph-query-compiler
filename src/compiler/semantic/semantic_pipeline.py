"""
Semantic Resolution Pipeline
============================

Orchestrates sequential semantic resolution stages inside the
graph query compiler.

This pipeline coordinates multiple resolvers and guarantees that:

1. The schema state is progressively refined.
2. Each stage operates on the output of the previous stage.
3. The original LLM schema is preserved.
4. All resolution steps are logged in a unified analysis structure.

Resolution Flow
---------------
1. EntityResolver          → Attribute validation and normalization
2. EntityTypeResolver      → Entity label/type correction
3. OperatorSemanticResolver → Numeric operator semantic validation

Input
-----
question : str
    Natural language user query.

llm_schema : dict
    Schema generated by the LLM.

Output
------
dict
    Dictionary containing:
        - question        : Original user question
        - original_schema : Unmodified LLM schema
        - resolved_schema : Fully refined schema after all passes
        - analysis        : Aggregated resolution logs by stage
"""

from copy import deepcopy


class SemanticResolutionPipeline:
    """
    Coordinates and executes semantic resolver passes in sequence,
    maintaining a consistent schema state across stages.
    """

    def __init__(
        self,
        entity_resolver,
        entity_type_resolver,
        operator_resolver
    ):
        """
        Parameters
        ----------
        entity_resolver : object
            Component responsible for attribute validation.
        entity_type_resolver : object
            Component responsible for entity label/type correction.
        operator_resolver : object
            Component responsible for operator semantic validation.
        """

        self.entity_resolver = entity_resolver
        self.entity_type_resolver = entity_type_resolver
        self.operator_resolver = operator_resolver

    # -----------------------------------------------------
    # Main Pipeline Entry
    # -----------------------------------------------------

    def resolve(self, question: str, llm_schema: dict) -> dict:
        """
        Executes all semantic resolution stages sequentially.

        Returns
        -------
        dict
            Unified resolution state after all passes.
        """

        # Initialize unified pipeline state
        state = {
            "question": question,
            "original_schema": deepcopy(llm_schema),
            "resolved_schema": deepcopy(llm_schema),
            "analysis": {}
        }

        # 1 — Attribute validation and normalization
        state = self._run_stage(
            state=state,
            resolver=self.entity_resolver,
            resolver_name="entity_resolver",
            question=question,
            llm_schema=state["resolved_schema"]
        )

        # 2 — Entity label/type correction
        state = self._run_stage(
            state=state,
            resolver=self.entity_type_resolver,
            resolver_name="entity_type_resolver",
            schema=state["resolved_schema"]
        )

        # 3 — Numeric operator semantic validation
        state = self._run_stage(
            state=state,
            resolver=self.operator_resolver,
            resolver_name="operator_resolver",
            question=question,
            schema_state=state
        )

        return state

    # -----------------------------------------------------
    # Stage Execution Wrapper
    # -----------------------------------------------------

    def _run_stage(
        self,
        state: dict,
        resolver,
        resolver_name: str,
        **kwargs
    ) -> dict:
        """
        Executes a single resolver stage and safely merges:

        - Resolved schema
        - Analysis output

        Parameters
        ----------
        state : dict
            Current pipeline state.
        resolver : object
            Resolver component with a `resolve` method.
        resolver_name : str
            Identifier used to log analysis results.
        **kwargs :
            Arguments forwarded to the resolver.

        Returns
        -------
        dict
            Updated pipeline state.
        """

        # Execute resolver
        new_state = resolver.resolve(**kwargs)

        # Ensure analysis is always stored as a list
        resolver_analysis = new_state.get("analysis", [])
        if not isinstance(resolver_analysis, list):
            resolver_analysis = [resolver_analysis]

        # Merge stage analysis into global analysis structure
        merged_analysis = dict(state.get("analysis", {}))
        merged_analysis[resolver_name] = resolver_analysis

        # Propagate updated schema (fallback to previous if missing)
        resolved_schema = new_state.get(
            "resolved_schema",
            state["resolved_schema"]
        )

        return {
            "question": state["question"],
            "original_schema": state["original_schema"],
            "resolved_schema": resolved_schema,
            "analysis": merged_analysis
        }
